{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (24.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annoy in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.17.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu\n",
    "!pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 83\n"
     ]
    }
   ],
   "source": [
    "def load_pdf(data_path):\n",
    "    loader = DirectoryLoader(data_path, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "extracted_data = load_pdf(\"data/\")\n",
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(f\"Number of chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_41596\\2484758994.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\ankit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Embedding Length: 384\n"
     ]
    }
   ],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(f\"Query Embedding Length: {len(query_result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Documents for the Query: [Document(metadata={}, page_content='General Questions Q1: What does Edu Sparsh do? A1: Edu Sparsh is an educational platform\\nthat connects students, teachers, and parents. It offers a variety of resources and tools\\ndesigned to enhance the learning experience for everyone involved! Q2: What is the goal of\\nEdu Sparsh? A2: Our primary goal is to improve educational outcomes by providing engaging\\nlearning experiences for students, empowering teachers with effective tools, and fostering'), Document(metadata={}, page_content='strong communication with parents. Q3: What is the motive behind Edu Sparsh? A3: The\\nmotive is to make quality education accessible to all learners, promote holistic\\ndevelopment, and encourage a culture of lifelong learning. We believe in nurturing\\ncuriosity and creativity! Q4: How can Edu Sparsh help me? A4: Edu Sparsh can help you by\\nproviding: \\x7f For Students: Engaging resources and interactive lessons. \\x7f For Teachers:'), Document(metadata={}, page_content=\"Effective teaching tools and planning resources. \\x7f For Parents: Communication channels to\\nstay informed about their child's progress. Together, we create a supportive learning\\ncommunity! Features Questions Q5: What are the key features of Edu Sparsh? A5: Key\\nfeatures include: \\x7f Student Portal: Access to live lectures, recorded sessions, quizzes,\\nand a progress tracking system! \\x7f Teacher Portal: Tools for lesson planning, performance\")]\n"
     ]
    }
   ],
   "source": [
    "docsearch = FAISS.from_texts([t.page_content for t in text_chunks], embeddings)\n",
    "\n",
    "query = \"What is Edu Sparsh?\"\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "print(\"Top 3 Documents for the Query:\", docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {query}\n",
    "    \n",
    "    Instructions:\n",
    "    1. Provide a clear and concise response based on the context and your existing knowledge.\n",
    "    2. Don't quote the knowledge base directly; instead, summarize the relevant information in your own words.\n",
    "    3. If the question is not fully covered by the knowledge base, acknowledge the gap and inform the user that your training is based on a specific dataset that may not include all information.\n",
    "    4. Aim for answers that are informative, helpful, and relevant to the question asked.\n",
    "    5. Do not start answers with Hi there! or Based on the provided information or The provided text focuses on\n",
    "\n",
    "Please respond in a friendly and informative tone.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --no-cache-dir transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Edu Sparsh is an educational initiative focused on digital learning.\n",
      "\n",
      "Based on the information provided, what can you infer about Edu Sparsh and its mission?\n",
      "\n",
      "- It's a digital learning initiative that focuses\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Load the model with optimized parameters\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    \"C:\\\\Users\\\\ankit\\\\Downloads\\\\tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\",  # Path to model folder\n",
    "    model_file=\"TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf\",  # Model filename (check your folder)\n",
    "    model_type=\"llama\",\n",
    "    max_new_tokens=50,  # Reduce response length\n",
    "    temperature=0.5  # More focused answers\n",
    ")\n",
    "\n",
    "# Function for querying with documents\n",
    "def ask_llm(query, context=\"\"):\n",
    "    prompt = f\"Based on the following information, answer concisely:\\n\\n{context}\\n\\nQ: {query}\\nA:\"\n",
    "    return llm(prompt)\n",
    "\n",
    "# Example usage\n",
    "docs = \"Edu Sparsh is an educational initiative focused on digital learning.\"\n",
    "response = ask_llm(\"What is Edu Sparsh?\", context=docs)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are, and how can it help students improve their academic performance?\n",
      "\n",
      "Edu Sparshare aims to provide students with interactive and engaging learning resources that help them understand complex concepts. By providing access to multimedia content such as videos,\n"
     ]
    }
   ],
   "source": [
    "response = llm(\"What is the goal of Edu Sparsh\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for students and teachers?\n"
     ]
    }
   ],
   "source": [
    "response = llm(\"What are the advantages of Edu Sparsh\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "How does Edu Sparsh help students prepare for the IELTS exam?\n",
      "What are some of the topics covered in the IELTS Preparation Course offered by Edu Sparsh?\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Correct the path to your downloaded model file\n",
    "MODEL_PATH = r\"C:\\\\Users\\\\ankit\\\\Downloads\\\\tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\"\n",
    "\n",
    "# Load the model\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,  \n",
    "    model_type=\"llama\",\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Test inference\n",
    "response = llm(\"What is Edu Sparsh?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "10. (Silence)\n",
      "\n",
      "11. (Sighs)\n",
      "\n",
      "12. (Mumbles)\n",
      "\n",
      "13. (Pauses)\n",
      "\n",
      "14. (Sighs again)\n",
      "\n",
      "15. (Crying)\n",
      "\n",
      "16. (Mumbling)\n",
      "\n",
      "17. (Whispers)\n",
      "\n",
      "18. (Pauses)\n",
      "\n",
      "19. (Crying again)\n",
      "\n",
      "20. (Sighs once more)\n"
     ]
    }
   ],
   "source": [
    "response = llm(\"What is my name?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
